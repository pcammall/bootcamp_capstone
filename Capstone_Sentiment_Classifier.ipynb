{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f137c340",
   "metadata": {},
   "source": [
    "# Sentiment Classifier\n",
    "\n",
    "This is a a sentiment classifer using Random Forest. The data sets are pulled from Kaggle:\n",
    "__link_here__\n",
    "\n",
    "\n",
    "First, begin by importing several items needed for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "740f1554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aebb002",
   "metadata": {},
   "source": [
    "## Data Exploration and Cleansing\n",
    "\n",
    "There's some additional items to import that will help with cleaning the input data. The input is text, and need to undergo some cleansing to reach a more standardized form before it is given to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aefb1790",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re #regular expressions\n",
    "import string\n",
    "import nltk #Natural Language \n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46cb72bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PGNX  Over 3.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AAP - user if so then the current downtrend wi...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Monday's relative weakness. NYX WIN TIE TAP IC...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GOOG - ower trend line channel test &amp; volume s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AAP will watch tomorrow for ONG entry.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i'm assuming FCX opens tomorrow above the 34.2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>It really worries me how everyone expects the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AAP GAMCO's arry Haverty : Apple Is Extremely ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>user Maykiljil posted that.  I agree that MSFT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Momentum is coming back to ETFC Broke MA200 re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>HA Hitting 35.65 means resume targeting 42 lev...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>user gameplan shot for today but I liked  on t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>with FCX gapping well above ideal entry lookin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>user great list again, particularly like FISV ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ATHX upper trend line</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NG - nice PNF BY - breakout - need follow thru</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Won't believe AAP uptrend is back until it cro...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>X swing still on</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SWY - 30% of float short and breaking out - ouch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BIOF wants 4.90's comin!!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>VS inverted head and shoulder play out well. W...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>red, not ready for break out.</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>EI close to breaking out now.  My trigger is a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>user BAC For a quick Trade to late..But for in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>CHDN - ong   49.02. Trailing Stop  56.66 from ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>AAP VOME today is impressive. At this rate and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  sentiment\n",
       "0   user: AAP MOVIE. 55% return for the FEA/GEED i...          1\n",
       "1   user I'd be afraid to short AMZN - they are lo...          1\n",
       "2                                   MNTA Over 12.00            1\n",
       "3                                    OI  Over 21.37            1\n",
       "4                                   PGNX  Over 3.04            1\n",
       "5   AAP - user if so then the current downtrend wi...         -1\n",
       "6   Monday's relative weakness. NYX WIN TIE TAP IC...         -1\n",
       "7   GOOG - ower trend line channel test & volume s...          1\n",
       "8              AAP will watch tomorrow for ONG entry.          1\n",
       "9   i'm assuming FCX opens tomorrow above the 34.2...          1\n",
       "10  It really worries me how everyone expects the ...          1\n",
       "11  AAP GAMCO's arry Haverty : Apple Is Extremely ...          1\n",
       "12  user Maykiljil posted that.  I agree that MSFT...          1\n",
       "13  Momentum is coming back to ETFC Broke MA200 re...          1\n",
       "14  HA Hitting 35.65 means resume targeting 42 lev...          1\n",
       "15  user gameplan shot for today but I liked  on t...          1\n",
       "16  with FCX gapping well above ideal entry lookin...          1\n",
       "17  user great list again, particularly like FISV ...          1\n",
       "18                           ATHX upper trend line             1\n",
       "19   NG - nice PNF BY - breakout - need follow thru            1\n",
       "20  Won't believe AAP uptrend is back until it cro...         -1\n",
       "21                                X swing still on             1\n",
       "22   SWY - 30% of float short and breaking out - ouch          1\n",
       "23                         BIOF wants 4.90's comin!!!          1\n",
       "24  VS inverted head and shoulder play out well. W...          1\n",
       "25                      red, not ready for break out.         -1\n",
       "26  EI close to breaking out now.  My trigger is a...          1\n",
       "27  user BAC For a quick Trade to late..But for in...          1\n",
       "28  CHDN - ong   49.02. Trailing Stop  56.66 from ...          1\n",
       "29  AAP VOME today is impressive. At this rate and...          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input_data = pd.read_csv(r'C:\\Users\\Patrick\\Documents\\GitHub\\bootcamp_capstone\\kaggle_dataset\\sentiment_analysis_financial_news\\all-data.csv'\n",
    "#                , encoding = \"ISO-8859-1\", header=None, names=['sentiment', 'text'])\n",
    "\n",
    "input_data = pd.read_csv(r'C:\\Users\\Patrick\\Documents\\GitHub\\bootcamp_capstone\\kaggle_dataset\\stock-market_sentiment\\stock_data.csv',\n",
    "                        encoding=\"ISO-8859-1\", header=1, names=['text', 'sentiment'] )\n",
    "\n",
    "input_data.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c5a93f",
   "metadata": {},
   "source": [
    "A quick preview of the data shows that the data lacks a consistent form. Some rows have special characters, while others have none at all; each line is of a different length; there is no consistent form.\n",
    "The cleanup begins by removing special characters, and converting everything to lower case. Then, prefixes and suffixes can be removed (lemmatizing), reducing words to ty and get a level of consistency. \n",
    "\n",
    "Stopwords are also removed. These are sentence modifiers like \"A\", \"The\", \"And\", \"This\". They don't add much information to a sentence, but exist because of grammar rules for human readabilty. They aren't necessary for the ML Model to extract the sentinment. The stopwords here will default to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04235133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Patrick\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "pattern = r'[^a-zA-Z0-9\\s\\%]'\n",
    "cleaned_buffer = []\n",
    "for x in input_data['text']:\n",
    "    temp = re.sub(pattern, \" \", x)\n",
    "    temp = temp.lower()\n",
    "    temp = temp.split()\n",
    "    temp = [lemmatizer.lemmatize(word) for word in temp if not word in set(stopwords)]\n",
    "    temp = ' '.join(temp)\n",
    "    cleaned_buffer.append(temp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d861e1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "      <td>user aap movie 55% return fea geed indicator 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>user afraid short amzn looking like near monop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1</td>\n",
       "      <td>mnta 12 00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1</td>\n",
       "      <td>oi 21 37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PGNX  Over 3.04</td>\n",
       "      <td>1</td>\n",
       "      <td>pgnx 3 04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AAP - user if so then the current downtrend wi...</td>\n",
       "      <td>-1</td>\n",
       "      <td>aap user current downtrend break otherwise sho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Monday's relative weakness. NYX WIN TIE TAP IC...</td>\n",
       "      <td>-1</td>\n",
       "      <td>monday relative weakness nyx win tie tap ice i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GOOG - ower trend line channel test &amp; volume s...</td>\n",
       "      <td>1</td>\n",
       "      <td>goog ower trend line channel test volume support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AAP will watch tomorrow for ONG entry.</td>\n",
       "      <td>1</td>\n",
       "      <td>aap watch tomorrow ong entry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i'm assuming FCX opens tomorrow above the 34.2...</td>\n",
       "      <td>1</td>\n",
       "      <td>assuming fcx open tomorrow 34 25 trigger buy s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment  \\\n",
       "0  user: AAP MOVIE. 55% return for the FEA/GEED i...          1   \n",
       "1  user I'd be afraid to short AMZN - they are lo...          1   \n",
       "2                                  MNTA Over 12.00            1   \n",
       "3                                   OI  Over 21.37            1   \n",
       "4                                  PGNX  Over 3.04            1   \n",
       "5  AAP - user if so then the current downtrend wi...         -1   \n",
       "6  Monday's relative weakness. NYX WIN TIE TAP IC...         -1   \n",
       "7  GOOG - ower trend line channel test & volume s...          1   \n",
       "8             AAP will watch tomorrow for ONG entry.          1   \n",
       "9  i'm assuming FCX opens tomorrow above the 34.2...          1   \n",
       "\n",
       "                                             cleaned  \n",
       "0  user aap movie 55% return fea geed indicator 1...  \n",
       "1  user afraid short amzn looking like near monop...  \n",
       "2                                         mnta 12 00  \n",
       "3                                           oi 21 37  \n",
       "4                                          pgnx 3 04  \n",
       "5  aap user current downtrend break otherwise sho...  \n",
       "6  monday relative weakness nyx win tie tap ice i...  \n",
       "7   goog ower trend line channel test volume support  \n",
       "8                       aap watch tomorrow ong entry  \n",
       "9  assuming fcx open tomorrow 34 25 trigger buy s...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data['cleaned'] = cleaned_buffer\n",
    "input_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fe4ea5",
   "metadata": {},
   "source": [
    "In some cases, the data cleansing has removed more information that necessary, making the resulting statement rather meaningless (rows 2, 3, and 4 above). With the additional rows of data, this can be overcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ac458b",
   "metadata": {},
   "source": [
    "## Creating Training and Test Data\n",
    "\n",
    "Now that the data is cleansed, the next step is to split it into a training and a test set. The data must also be converted into a number format, as the Machine Learning model cannot comprehend text. \n",
    "\n",
    "Converting the input data into numbers is done with a TFIDF Vectorizer. This will look at the words in the given input, and generate a mapping of which word(s) go together and how often. It's set to do up to 3 words at a time. The TFIDF is extracting features that the ML Model will use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ced720d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split( input_data['cleaned'], input_data['sentiment'],\n",
    "                                                               test_size=.4, random_state=10)\n",
    "#60% of the data will be used for training. 40% to test.\n",
    "#the random state number is so that each time this is run it generates the same result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "002c76a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1,3))\n",
    "xtrain_tf = tfidf.fit_transform(xtrain)\n",
    "xtest_tf = tfidf.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84ae9a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nsamples: 2316, nfeatures: 57630\n",
      "  (0, 45368)\t0.510097570366633\n",
      "  (0, 25696)\t0.510097570366633\n",
      "  (0, 25695)\t0.510097570366633\n",
      "  (0, 14855)\t0.3210467802934407\n",
      "  (0, 12960)\t0.3410723837858898\n",
      "  (1, 31576)\t0.822655797157474\n",
      "  (1, 31525)\t0.4690720683613014\n",
      "  (1, 5270)\t0.32126131744492964\n"
     ]
    }
   ],
   "source": [
    "print(\"nsamples: %d, nfeatures: %d\" % xtest_tf.shape)\n",
    "print(xtest_tf[1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdcf521",
   "metadata": {},
   "source": [
    "need to talk about the tfidf matrix. maybe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccd9d2a",
   "metadata": {},
   "source": [
    "Now for actually building and training the model. The model is a Random Forest Classifier from SciKitLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05b24811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76546763 0.73956835 0.75251799 0.7381295  0.72622478]\n"
     ]
    }
   ],
   "source": [
    "rand_forest = RandomForestClassifier()\n",
    "scores = cross_val_score(rand_forest, xtrain_tf, ytrain, cv=5)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6aec4d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [2, 5, 10, 20, None],\n",
       "                         'n_estimators': [5, 10, 25, 50, 100]})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a basic version of hyperparameter tuning, to try and make this a bit better\n",
    "params = { 'n_estimators' : [5, 10, 25, 50, 100], 'max_depth' : [2, 5, 10, 20, None]}\n",
    "\n",
    "grid_search = GridSearchCV (rand_forest, params)\n",
    "grid_search.fit(xtrain_tf, ytrain.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
